import asyncio
import json
import os
from datetime import datetime
from openai import AsyncOpenAI
from tools.bgp_toolkit import BGPToolKit
from tools.rag_manager import RAGManager

# --- é…ç½® ---
# è¯·ç¡®ä¿è¿™æ˜¯æœ‰æ•ˆçš„ DeepSeek API Key
API_KEY = "sk-9944c48494394db6b8bc31b40f8a710f"
BASE_URL = "https://api.deepseek.com"

class BGPAgent:
    def __init__(self, report_dir="./report"):
        """
        åˆå§‹åŒ– BGP Agent
        :param report_dir: æŠ¥å‘Šå­˜å‚¨ç›®å½•
        """
        self.client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)
        
        # 1. åˆå§‹åŒ–å·¥å…·ç®± (ç”¨äºæŸ¥è¯¢ RPKI, Geo ç­‰)
        self.toolkit = BGPToolKit()
        
        # 2. åˆå§‹åŒ– RAG å¼•æ“ (æŒ‡å‘æˆ‘ä»¬åˆšæ‰ä¿®å¤å¥½çš„æ–°æ•°æ®åº“)
        # æ³¨æ„ï¼šè¿™é‡Œå¿…é¡»å’Œ fix_rag_data.py é‡Œç”Ÿæˆçš„è·¯å¾„ä¸€è‡´
        self.rag = RAGManager(db_path="./rag_db_new")
        
        self.report_dir = report_dir
        
        # åŸºç¡€ Promptæ¨¡æ¿ (åç»­ä¼šè¢«åŠ¨æ€ RAG å†…å®¹å¡«å……)
        self.base_system_prompt = """
ä½ æ˜¯ä¸€ä¸ª BGP å®‰å…¨ä¸“å®¶ Agentã€‚ä½ çš„ç›®æ ‡æ˜¯ç»“åˆã€å†å²æ¡ˆä¾‹çŸ¥è¯†ã€‘å’Œã€å®æ—¶å·¥å…·æ£€æµ‹ã€‘ï¼Œå¯¹ BGP å¼‚å¸¸è¿›è¡Œå®šæ€§ã€‚

**å¯ç”¨å·¥å…·:**
1. `authority_check`: æŸ¥è¯¢ RPKI æˆæƒçŠ¶æ€ (æ£€æŸ¥ Origin AS æ˜¯å¦åˆæ³•)ã€‚
2. `geo_check`: æ£€æŸ¥ IP å’Œ ASN çš„åœ°ç†ä½ç½® (æ£€æŸ¥è·¨å›½å†²çª)ã€‚
3. `neighbor_check`: æ£€æŸ¥ä¼ æ’­è¯¥è·¯ç”±çš„ä¸Šæ¸¸é‚»å±… (AS 174, 3356 ç­‰)ã€‚
4. `topology_check`: æ£€æŸ¥ AS è·¯å¾„çš„å•†ä¸šå…³ç³» (æ£€æŸ¥è·¯ç”±æ³„éœ²)ã€‚

**å·¥ä½œæµç¨‹:**
è¿™æ˜¯ä¸€ä¸ªæœ€å¤š 3 è½®çš„å¯¹è¯ã€‚
- ç¬¬ 1-2 è½®: æ ¹æ®ç°æœ‰ä¿¡æ¯ï¼Œå†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·è·å–æ›´å¤šè¯æ®ã€‚
- ç¬¬ 3 è½®: å¿…é¡»ç»“åˆæ‰€æœ‰è¯æ®ç»™å‡ºæœ€ç»ˆç»“è®º (final_decision)ã€‚

**è¾“å‡º JSON æ ¼å¼:**
{
    "round_id": int,
    "thought_process": "æ€ç»´é“¾ï¼šåˆ†æå½“å‰æƒ…å†µï¼Œå¯¹æ¯”å†å²æ¡ˆä¾‹ï¼Œå†³å®šä¸‹ä¸€æ­¥...",
    "suspicion_level": "low/medium/high", 
    "tool_request": "tool_name" | null,
    "final_decision": {
        "status": "MALICIOUS" | "BENIGN" | "UNKNOWN",
        "summary": "æœ€ç»ˆç»“è®ºæ‘˜è¦..."
    }
}
"""

    async def _call_llm(self, messages):
        """è°ƒç”¨ DeepSeek å¤§æ¨¡å‹"""
        try:
            response = await self.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                response_format={'type': 'json_object'},
                temperature=0.0 # 0 æ¸©åº¦ä¿è¯é€»è¾‘ä¸¥è°¨
            )
            content = response.choices[0].message.content
            return json.loads(content)
        except Exception as e:
            # ç®€å•çš„é”™è¯¯å¤„ç†ï¼Œé˜²æ­¢å•æ¬¡ API å¤±è´¥å¯¼è‡´å´©ç›˜
            return {"thought_process": f"API Error: {str(e)}", "tool_request": None}

    def _save_report_to_disk(self, trace_data):
        """å°†å®Œæ•´æ€ç»´é“¾ä¿å­˜ä¸º JSON æ–‡ä»¶"""
        if not os.path.exists(self.report_dir):
            os.makedirs(self.report_dir, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶å (å®‰å…¨å¤„ç† / è½¬ä¸º _)
        raw_prefix = trace_data.get("target", {}).get("prefix", "unknown")
        safe_prefix = raw_prefix.replace("/", "_")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        filename = f"analysis_{safe_prefix}_{timestamp}.json"
        file_path = os.path.join(self.report_dir, filename)

        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(trace_data, f, indent=4, ensure_ascii=False)
            print(f"ğŸ’¾ [Agent] æŠ¥å‘Šå·²è‡ªåŠ¨å½’æ¡£: {file_path}")
        except Exception as e:
            print(f"âŒ [Agent] ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

    async def diagnose(self, alert_context, verbose=False):
        """
        æ ¸å¿ƒè¯Šæ–­æµç¨‹
        :param alert_context: å¼‚å¸¸ä¸Šä¸‹æ–‡ (Prefix, Path, Origin...)
        :param verbose: æ˜¯å¦æ‰“å°è¯¦ç»†æ—¥å¿— (å¹¶å‘æ¨¡å¼å»ºè®® False)
        """
        if verbose:
            print(f"\nğŸ›¡ï¸  [Agent] å¼€å§‹è¯Šæ–­: {alert_context.get('prefix')}...")

        # --- Phase 1: RAG çŸ¥è¯†æ£€ç´¢ ---
        # æ— è®º verbose æ˜¯å¦å¼€å¯ï¼Œæˆ‘ä»¬å…ˆæŸ¥çŸ¥è¯†åº“
        try:
            retrieved_knowledge = self.rag.search_similar_cases(alert_context, k=2)
            
            # [è°ƒè¯•åé¦ˆ] å¦‚æœæ£€ç´¢åˆ°äº†å†…å®¹ï¼Œä¸”ä¸æ˜¯â€œæœªæ‰¾åˆ°â€ï¼Œåœ¨æ§åˆ¶å°é—ªä¸€ä¸‹ï¼Œè®©ä½ çŸ¥é“ RAG åœ¨å·¥ä½œ
            if "æœªæ‰¾åˆ°ç›¸ä¼¼å†å²æ¡ˆä¾‹" not in retrieved_knowledge:
                print(f"ğŸ“š [RAG å‘½ä¸­] Agent å·²æ£€ç´¢åˆ°å…³äº {alert_context.get('prefix')} çš„ç›¸ä¼¼å†å²æ¡ˆä¾‹ï¼")
                
        except Exception as e:
            retrieved_knowledge = f"(RAG æ£€ç´¢ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨: {e})"

        # --- Phase 2: æ„å»ºåŠ¨æ€ Prompt ---
        dynamic_prompt = f"""
{self.base_system_prompt}

ã€ğŸ§  å†å²çŸ¥è¯†åº“å‚è€ƒ (RAG)ã€‘
ä»¥ä¸‹æ˜¯ç³»ç»Ÿæ£€ç´¢åˆ°çš„æœ€ç›¸ä¼¼å†å²æ¡ˆä¾‹ï¼Œè¯·åˆ©ç”¨å®ƒä»¬è¿›è¡Œç±»æ¯”æ¨ç† (Case-Based Reasoning)ï¼š
{retrieved_knowledge}

ã€å½“å‰å¾…åˆ†æå‘Šè­¦ã€‘
Prefix: {alert_context.get('prefix')}
Path: {alert_context.get('as_path')}
Origin: {alert_context.get('detected_origin')}
Expected Origin: {alert_context.get('expected_origin')}
"""

        messages = [
            {"role": "system", "content": dynamic_prompt},
            {"role": "user", "content": "æ£€æµ‹åˆ° BGP å¼‚å¸¸ï¼Œè¯·å¼€å§‹åˆ†æã€‚"}
        ]
        
        # åˆå§‹åŒ–å®Œæ•´è¿½è¸ªè®°å½•
        full_trace = {
            "target": alert_context,
            "start_time": datetime.now().isoformat(),
            "rag_context": retrieved_knowledge, # è®°å½• RAG ç»“æœä»¥ä¾¿åç»­å®¡è®¡
            "chain_of_thought": [],
            "final_result": None
        }

        # --- Phase 3: å¤šè½®æ¨ç†å¾ªç¯ ---
        for round_idx in range(1, 4):
            if verbose: print(f"--- Round {round_idx} ---")
            
            # 1. AI æ€è€ƒ
            response_json = await self._call_llm(messages)
            if not response_json: break
            
            # åˆå§‹åŒ–æœ¬è½®è®°å½•
            trace_item = {
                "round": round_idx,
                "ai_thought": response_json.get("thought_process"),
                "suspicion": response_json.get("suspicion_level"),
                "tool_used": response_json.get("tool_request"),
                "tool_output": None
            }

            # ---------------- å…³é”®ä¿®æ”¹å¼€å§‹ ----------------
            tool_name = response_json.get("tool_request")
            final_decision = response_json.get("final_decision")

            # é€»è¾‘ä¿®æ­£ï¼šåªè¦æœ‰å·¥å…·è¯·æ±‚ï¼Œå°±ä¼˜å…ˆæ‰§è¡Œå·¥å…·ï¼Œæ— è§† final_decision
            if tool_name:
                if verbose: print(f"ğŸ› ï¸  Calling: {tool_name}")
                
                # æ‰§è¡Œå·¥å…·
                tool_result_str = self.toolkit.call_tool(tool_name, alert_context)
                trace_item["tool_output"] = tool_result_str
                
                # è®°å½•æœ¬è½®
                full_trace["chain_of_thought"].append(trace_item)
                
                # æ›´æ–°å¯¹è¯å†å²ï¼Œå¼ºåˆ¶è¿›å…¥ä¸‹ä¸€è½®
                messages.append({"role": "assistant", "content": json.dumps(response_json)})
                messages.append({"role": "user", "content": f"ã€å·¥å…·åé¦ˆã€‘\n{tool_result_str}\n\nè¯·æ ¹æ®å·¥å…·ç»“æœç»§ç»­åˆ†æ (ä¸è¦è¿‡æ—©ä¸‹ç»“è®º)ã€‚"})
                
                # âš ï¸ å…³é”®ï¼šç›´æ¥ continueï¼Œè·³è¿‡ä¸‹é¢çš„ç»“æ¡ˆåˆ¤æ–­
                continue

            # åªæœ‰åœ¨ã€æ²¡æœ‰ã€‘è¯·æ±‚å·¥å…·çš„æƒ…å†µä¸‹ï¼Œæ‰å…è®¸ç»“æ¡ˆ
            if final_decision:
                full_trace["final_result"] = final_decision
                full_trace["chain_of_thought"].append(trace_item)
                if verbose: print("âœ… è¯Šæ–­ç»“æŸ (è‡ªä¸»ç»“æ¡ˆ)ã€‚")
                self._save_report_to_disk(full_trace)
                return full_trace
            # ---------------- å…³é”®ä¿®æ”¹ç»“æŸ ----------------

            # å¦‚æœæ—¢æ²¡å·¥å…·ä¹Ÿæ²¡ç»“è®ºï¼ˆæå…¶ç½•è§ï¼‰ï¼Œè®°å½•å¹¶ç»§ç»­
            full_trace["chain_of_thought"].append(trace_item)
            messages.append({"role": "assistant", "content": json.dumps(response_json)})
            messages.append({"role": "user", "content": "è¯·ç»§ç»­åˆ†æï¼Œæˆ–è€…ç»™å‡º final_decisionã€‚"})

        # --- Phase 4: å¼ºåˆ¶ç»“ç®— (Safety Net) ---
        # å¦‚æœè·‘äº† 3 è½®è¿˜æ²¡ç»“è®ºï¼Œå¼ºåˆ¶ AI æ€»ç»“
        if full_trace["final_result"] is None:
            if verbose: print("âš ï¸ è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼Œå¼ºåˆ¶ç»“ç®—...")
            
            messages.append({
                "role": "user", 
                "content": "ã€ç³»ç»ŸæŒ‡ä»¤ã€‘å·²è¾¾åˆ°æœ€å¤§åˆ†æè½®æ¬¡ã€‚è¯·å¿½ç•¥æœªå®Œæˆçš„å·¥å…·è°ƒç”¨ï¼Œæ ¹æ®ç°æœ‰çš„ RAG çŸ¥è¯†ã€RPKI çŠ¶æ€å’Œåœ°ç†ä½ç½®è¯æ®ï¼Œå¿…é¡»ç«‹å³ç”Ÿæˆ final_decision JSONã€‚"
            })
            
            final_resp = await self._call_llm(messages)
            
            if final_resp and final_resp.get("final_decision"):
                full_trace["final_result"] = final_resp.get("final_decision")
                full_trace["chain_of_thought"].append({
                    "round": "Final_Summary",
                    "ai_thought": final_resp.get("thought_process", "Forced Summary"),
                    "suspicion": final_resp.get("suspicion_level"),
                    "tool_used": None
                })

        # ä¿å­˜å¹¶è¿”å›
        self._save_report_to_disk(full_trace)
        return full_trace

if __name__ == "__main__":
    # ç®€å•è‡ªæµ‹
    agent = BGPAgent()
    test_data = {
        "prefix": "104.244.42.0/24", 
        "as_path": "174 12389", 
        "detected_origin": "12389",
        "expected_origin": "13414"
    }
    asyncio.run(agent.diagnose(test_data, verbose=True))