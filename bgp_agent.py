import asyncio
import json
import os
import traceback
from datetime import datetime
from openai import AsyncOpenAI
from tools.bgp_toolkit import BGPToolKit
from tools.rag_manager import RAGManager

# --- é…ç½® ---
API_KEY = "sk-9944c48494394db6b8bc31b40f8a710f"
BASE_URL = "https://api.deepseek.com"

class BGPAgent:
    def __init__(self, report_dir="./report"):
        """
        åˆå§‹åŒ– BGP æº¯æº Agent
        """
        self.client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)
        
        # 1. åˆå§‹åŒ–å·¥å…·ç®±
        self.toolkit = BGPToolKit()
        
        # 2. åˆå§‹åŒ– RAG (æŒ‡å‘æº¯æºä¸“ç”¨æ•°æ®åº“)
        # æ³¨æ„: è¯·ç¡®ä¿ä½ è¿è¡Œäº† gen_forensics_data.py å¹¶æ„å»ºäº†æ­¤æ•°æ®åº“
        db_path = "./rag_db"
        
        # ä¸ºäº†é˜²æ­¢ç›®å½•ä¸å­˜åœ¨æŠ¥é”™ï¼ŒåŠ ä¸ªåˆ¤æ–­ï¼Œå¦‚æœæ–°åº“ä¸å­˜åœ¨åˆ™å›é€€åˆ°é»˜è®¤
        if not os.path.exists(db_path):
            print(f"âš ï¸ [Warning] æº¯æºæ•°æ®åº“ {db_path} æœªæ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤ ./rag_db")
            db_path = "./rag_db"
            
        self.rag = RAGManager(db_path=db_path)
        self.report_dir = report_dir

        # ==========================================
        # ğŸ¯ System Prompt: æº¯æºä¸“å®¶è®¾å®šï¼ˆå•æ¡ï¼‰
        # ==========================================
        self.base_system_prompt = """
ä½ æ˜¯ä¸€ä¸ª BGP å®‰å…¨æº¯æºä¸“å®¶ (Digital Forensics Expert)ã€‚
ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯åˆ†æ BGP è·¯ç”±æ›´æ–°ï¼Œå¹¶**æ‰¾å‡ºæ”»å‡»è€… (Attacker AS)**ã€‚

**æº¯æºåˆ†ææ–¹æ³•è®º (Methodology):**
1. **Path Forensics (è·¯å¾„å–è¯)**:
   - æ£€æŸ¥ `AS_PATH` å±æ€§ã€‚
   - è·¯å¾„æœ€å³ä¾§çš„ AS (Last Hop) æ˜¯ **Origin AS**ã€‚
   - å¦‚æœ Origin AS != Expected Ownerï¼Œä¸”æ— åˆæ³•æˆæƒï¼Œåˆ™è¯¥ Origin AS æ˜¯**é¦–è¦å«Œç–‘äºº (Primary Suspect)**ã€‚

2. **Route Leak (è·¯ç”±æ³„éœ²)**:
   - å¦‚æœ Origin æ­£ç¡®ï¼Œä½†è·¯å¾„è¿åå•†ä¸šå…³ç³» (ä¾‹å¦‚ Tier-1 äº’è”å‡ºç°å¼‚å¸¸)ï¼Œæ”»å‡»è€…å¯èƒ½æ˜¯è·¯å¾„ä¸­é—´çš„ ASã€‚

**å¯ç”¨å·¥å…·:**
- `path_forensics`: ä¸“é—¨ç”¨äºè§£æ AS Pathï¼Œæå– Origin å¹¶è‡ªåŠ¨åˆ¤å®šå«Œç–‘äººã€‚
- `graph_analysis`: æŸ¥è¯¢å›¾è°±ï¼ŒéªŒè¯å«Œç–‘äººä¸ Owner æ˜¯å¦æœ‰çœŸå®è¿æ¥ã€‚
- `authority_check`: æŸ¥è¯¢ RPKI æˆæƒã€‚

**âš ï¸ ä¸¥æ ¼è¾“å‡ºæ ¼å¼ (JSON):**
æ¯ä¸€æ¬¡å›å¤å¿…é¡»æ˜¯æ ‡å‡† JSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
    "thought_process": "ä½ çš„è¯¦ç»†æ¨ç†è¿‡ç¨‹ (æ€ç»´é“¾)...",
    "tool_request": "å·¥å…·åç§°å­—ç¬¦ä¸²" OR null,
    "final_decision": null OR {
        "status": "MALICIOUS" | "LEAK" | "BENIGN",
        "attacker_as": "ASxxxx" (å¿…é¡»æ˜ç¡®æŒ‡å‡ºï¼Œå¦‚æœæ˜¯è¯¯åˆ¤åˆ™å¡« 'None'),
        "summary": "ç®€çŸ­çš„ç»“æ¡ˆé™ˆè¯"
    }
}

**ç¦å¿Œ:**
- `tool_request` å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼Œä¸¥ç¦è¿”å›å­—å…¸/å¯¹è±¡ã€‚
- åªæœ‰åœ¨è¯æ®ç¡®å‡¿ï¼ˆå·²é”å®š Attacker AS æˆ–æ’é™¤æ”»å‡»ï¼‰æ—¶ï¼Œæ‰è¿”å› `final_decision`ã€‚
"""

        # ==========================================
        # ğŸ¯ Batch System Prompt: æ‰¹é‡å‘Šè­¦ç»¼åˆæº¯æº
        # ==========================================
        self.batch_system_prompt = """
ä½ æ˜¯ä¸€ä¸ª BGP å®‰å…¨æº¯æºä¸“å®¶ (Digital Forensics Expert)ã€‚
ä½ æ”¶åˆ°**ä¸€ä¸ªæ—¶é—´çª—å£å†…çš„å¤šæ¡å‘Šè­¦æ¶ˆæ¯**ï¼Œæ¯æ¡å‘Šè­¦åŒ…å«å¯ç–‘çš„ BGP Updateã€‚

**é‡è¦å‰æï¼š**
- å‘Šè­¦æ¶ˆæ¯ä¸ä¸€å®š 100% å‡†ç¡®ï¼Œå¯èƒ½å­˜åœ¨è¯¯æŠ¥æˆ–å™ªå£°ã€‚
- ä½ éœ€è¦**æ±‡æ€»æ‰€æœ‰ updates**ï¼Œç»¼åˆè¿›è¡Œå¼‚å¸¸æº¯æºåˆ†æã€‚
- è¾“å‡º**åŸºäºç›®å‰å¼‚å¸¸å‘Šè­¦æ¶ˆæ¯ã€æœ€æœ‰å¯èƒ½æ˜¯æ”»å‡»è€…çš„ AS å·**ï¼Œå¹¶ç»™å‡ºç½®ä¿¡åº¦ã€‚

**æº¯æºåˆ†ææ–¹æ³•è®º:**
1. **Path Forensics**: å¯¹æ¯æ¡ update æå– Originï¼Œç»Ÿè®¡å“ªäº› AS ä½œä¸ºå¯ç–‘ Origin å‡ºç°æœ€é¢‘ç¹ã€‚
2. **äº¤å‰éªŒè¯**: è‹¥å¤šæ¡ update æŒ‡å‘åŒä¸€ ASï¼Œåˆ™è¯¥ AS å«Œç–‘æ›´å¤§ï¼›è‹¥ç›¸äº’çŸ›ç›¾ï¼Œéœ€æƒè¡¡è¯æ®å¼ºåº¦ã€‚
3. **Route Leak**: è‹¥ Origin æ­£ç¡®ä½†è·¯å¾„å¼‚å¸¸ï¼Œæ”»å‡»è€…å¯èƒ½æ˜¯è·¯å¾„ä¸­é—´çš„ Leakerã€‚

**å¯ç”¨å·¥å…·:**
- `path_forensics`: å¯¹æ‰¹é‡ updates åšè·¯å¾„å–è¯ï¼Œè¿”å›æ¯æ¡çš„åˆ†æ + æ±‡æ€»ç»Ÿè®¡ã€‚
- `graph_analysis`: æŸ¥è¯¢å›¾è°±éªŒè¯å«Œç–‘äººä¸ Owner çš„æ‹“æ‰‘å…³ç³»ï¼ˆå¯æŒ‡å®šæŸæ¡ updateï¼‰ã€‚
- `authority_check`: æŸ¥è¯¢ RPKI æˆæƒï¼ˆå¯æŒ‡å®šæŸæ¡ updateï¼‰ã€‚

**âš ï¸ ä¸¥æ ¼è¾“å‡ºæ ¼å¼ (JSON):**
{
    "thought_process": "ä½ çš„è¯¦ç»†æ¨ç†è¿‡ç¨‹ï¼Œéœ€è€ƒè™‘å¤šæ¡å‘Šè­¦çš„ç»¼åˆè¯æ®...",
    "tool_request": "å·¥å…·åç§°å­—ç¬¦ä¸²" OR null,
    "final_decision": null OR {
        "status": "MALICIOUS" | "LEAK" | "BENIGN" | "UNCERTAIN",
        "most_likely_attacker": "ASxxxx" (åŸºäºç›®å‰å‘Šè­¦æœ€å¯èƒ½çš„æ”»å‡»è€…ï¼Œè‹¥æ— åˆ™å¡« 'None'),
        "confidence": "High" | "Medium" | "Low",
        "summary": "ç»¼åˆ X æ¡å‘Šè­¦æ¶ˆæ¯çš„åˆ†æç»“è®ºï¼Œè¯´æ˜ä¸ºä½•è¯¥ AS æœ€æœ‰å¯èƒ½æ˜¯æ”»å‡»è€…"
    }
}
"""

    async def _call_llm(self, messages):
        """è°ƒç”¨ DeepSeek API (JSON æ¨¡å¼)"""
        try:
            response = await self.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                response_format={'type': 'json_object'}, # å¼ºåˆ¶ JSON
                temperature=0.0 # é›¶æ¸©åº¦ï¼Œç¡®ä¿é€»è¾‘ä¸¥è°¨
            )
            content = response.choices[0].message.content
            return json.loads(content)
        except Exception as e:
            print(f"âŒ API è°ƒç”¨å¤±è´¥: {e}")
            return {"thought_process": f"API Error: {str(e)}", "tool_request": None}

    def _save_report(self, trace_data, is_batch=False):
        """å½’æ¡£åˆ†ææŠ¥å‘Š"""
        if not os.path.exists(self.report_dir):
            os.makedirs(self.report_dir, exist_ok=True)

        if is_batch:
            target = trace_data.get("target", {})
            updates = target.get("updates", [])
            prefix = updates[0].get("prefix", "unknown").replace("/", "_") if updates else "batch"
            timestamp = datetime.now().strftime("%H%M%S")
            filename = f"forensics_batch_{prefix}_{len(updates)}updates_{timestamp}.json"
        else:
            prefix = trace_data.get("target", {}).get("prefix", "unknown").replace("/", "_")
            timestamp = datetime.now().strftime("%H%M%S")
            filename = f"forensics_{prefix}_{timestamp}.json"
        
        try:
            with open(os.path.join(self.report_dir, filename), 'w', encoding='utf-8') as f:
                json.dump(trace_data, f, indent=4, ensure_ascii=False)
        except Exception:
            pass

    async def diagnose(self, alert_context, verbose=False):
        """
        æ‰§è¡Œè¯Šæ–­æµç¨‹
        """
        if verbose: 
            print(f"\nğŸ•µï¸â€â™‚ï¸ [Agent] å¼€å§‹æº¯æºå–è¯: {alert_context.get('prefix')} ...")

        # --- Phase 1: RAG çŸ¥è¯†æ£€ç´¢ ---
        try:
            # æœç´¢ç›¸ä¼¼çš„æº¯æºæ¡ˆä¾‹
            rag_knowledge = self.rag.search_similar_cases(alert_context, k=2)
            if verbose and "æœªæ‰¾åˆ°" not in str(rag_knowledge):
                print(f"ğŸ“š [RAG] å·²åŠ è½½å†å²æº¯æºæ¡£æ¡ˆ...")
        except Exception:
            rag_knowledge = "(RAG Database Unavailable)"

        # --- Phase 2: æ„é€ åŠ¨æ€ Prompt ---
        dynamic_prompt = f"""
{self.base_system_prompt}

ã€ğŸ“‚ å†å²æº¯æºæ¡£æ¡ˆ (RAG Reference)ã€‘
{rag_knowledge}

ã€ğŸš¨ å½“å‰æ¡ˆæƒ…è¯æ® (Evidence)ã€‘
- Target Prefix: {alert_context.get('prefix')}
- Suspicious AS_PATH: {alert_context.get('as_path')}
- Detected Origin: {alert_context.get('detected_origin')}
- Legitimate Owner: {alert_context.get('expected_origin')}
"""
        messages = [
            {"role": "system", "content": dynamic_prompt},
            {"role": "user", "content": "è¯·åˆ†æä¸Šè¿°è¯æ®ï¼Œä½¿ç”¨å·¥å…·æ‹†è§£è·¯å¾„ï¼Œå¹¶é”å®šæ”»å‡»è€… (Attacker AS)ã€‚"}
        ]
        
        trace = {
            "target": alert_context,
            "start_time": datetime.now().isoformat(),
            "rag_context": rag_knowledge,
            "chain_of_thought": [],
            "final_result": None
        }

        # --- Phase 3: æ¨ç†å¾ªç¯ (Max 3 Rounds) ---
        for round_idx in range(1, 4):
            if verbose: print(f"--- Round {round_idx} ---")
            
            # 1. AI æ€è€ƒ
            resp_json = await self._call_llm(messages)
            if not resp_json: break
            
            # 2. è§£æè¾“å‡º
            tool_req = resp_json.get("tool_request")
            final_decision = resp_json.get("final_decision")

            # === ğŸ›¡ï¸ é²æ£’æ€§é˜²å¾¡: æ¸…æ´—å·¥å…·å ===
            if tool_req:
                if isinstance(tool_req, dict):
                    # å¦‚æœ AI è¿˜æ˜¯è¿”å›äº†å­—å…¸ï¼Œæå–ç¬¬ä¸€ä¸ªå€¼
                    tool_req = list(tool_req.values())[0]
                tool_req = str(tool_req).strip()
                if tool_req.lower() == "none": tool_req = None
            # ==============================

            step_record = {
                "round": round_idx,
                "thought": resp_json.get("thought_process"),
                "ai_full_response": resp_json,
                "tool_used": tool_req,
                "tool_output": None
            }

            # 3. åˆ†æ”¯å¤„ç†
            # ä¼˜å…ˆæ‰§è¡Œå·¥å…·
            if tool_req:
                if verbose: print(f"ğŸ› ï¸  Agent è°ƒç”¨å·¥å…·: {tool_req}")
                
                tool_output = self.toolkit.call_tool(tool_req, alert_context)
                step_record["tool_output"] = tool_output
                trace["chain_of_thought"].append(step_record)
                
                # å°†å·¥å…·ç»“æœå–‚å›ç»™ AI
                messages.append({"role": "assistant", "content": json.dumps(resp_json)})
                messages.append({"role": "user", "content": f"ã€å·¥å…·ç»“æœã€‘\n{tool_output}\n\nè¯·æ ¹æ®ç»“æœåˆ¤æ–­ï¼šèƒ½å¦é”å®š Attacker ASï¼Ÿå¦‚æœèƒ½ï¼Œè¯·è¾“å‡º final_decisionã€‚"})
                continue
            
            # å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œæ£€æŸ¥æ˜¯å¦ç»“æ¡ˆ
            if final_decision:
                trace["final_result"] = final_decision
                trace["chain_of_thought"].append(step_record)
                if verbose: 
                    attacker = final_decision.get('attacker_as', 'Unknown')
                    print(f"âœ… ç»“æ¡ˆ! é”å®šæ”»å‡»è€…: {attacker}")
                
                self._save_report(trace)
                return trace

            # æ—¢æ²¡å·¥å…·ä¹Ÿæ²¡ç»“è®º (ç½•è§æƒ…å†µ)
            trace["chain_of_thought"].append(step_record)
            messages.append({"role": "assistant", "content": json.dumps(resp_json)})
            messages.append({"role": "user", "content": "è¯·ç»§ç»­åˆ†æã€‚"})

        # --- Phase 4: å¼ºåˆ¶ç»“ç®— ---
        if trace["final_result"] is None:
            if verbose: print("âš ï¸ å¼ºåˆ¶ç»“æ¡ˆ...")
            messages.append({"role": "user", "content": "åˆ†æç»“æŸã€‚è¯·å¿½ç•¥æœªå®Œæˆæ­¥éª¤ï¼Œç«‹å³è¾“å‡º JSONï¼Œå¿…é¡»åŒ…å« 'attacker_as'ã€‚"})
            final_resp = await self._call_llm(messages)
            if final_resp and final_resp.get("final_decision"):
                trace["final_result"] = final_resp.get("final_decision")
                trace["chain_of_thought"].append({
                    "round": "force",
                    "thought": final_resp.get("thought_process"),
                    "ai_full_response": final_resp,
                    "tool_used": None,
                    "tool_output": None,
                })

        self._save_report(trace)
        return trace

    async def diagnose_batch(self, alert_batch, verbose=False):
        """
        æ‰¹é‡å‘Šè­¦ç»¼åˆæº¯æºï¼šæ±‡æ€»æ—¶é—´çª—å£å†…å¤šæ¡ updatesï¼Œç»¼åˆåˆ†æï¼Œè¾“å‡ºæœ€æœ‰å¯èƒ½æ˜¯æ”»å‡»è€…çš„ ASã€‚

        è¾“å…¥æ ¼å¼:
        {
            "time_window": {"start": "...", "end": "..."},  # å¯é€‰
            "updates": [
                {"prefix": "8.8.8.0/24", "as_path": "701 174", "detected_origin": "174", "expected_origin": "15169"},
                {"prefix": "8.8.8.0/24", "as_path": "701 4761", "detected_origin": "4761", "expected_origin": "15169"},
                ...
            ]
        }
        """
        updates = alert_batch.get("updates", [])
        if not updates:
            return {"error": "updates ä¸èƒ½ä¸ºç©º", "final_result": None}

        if verbose:
            print(f"\nğŸ•µï¸â€â™‚ï¸ [Agent] æ‰¹é‡æº¯æº: å…± {len(updates)} æ¡å‘Šè­¦ updates ...")

        # --- Phase 1: RAG çŸ¥è¯†æ£€ç´¢ï¼ˆæ±‡æ€»æ‰€æœ‰ updates åˆ†åˆ«æŸ¥è¯¢ï¼Œåˆå¹¶å»é‡å– top-kï¼‰---
        try:
            rag_knowledge = self.rag.search_similar_cases_batch(updates, k=2)
            if verbose and "æœªæ‰¾åˆ°" not in str(rag_knowledge):
                print(f"ğŸ“š [RAG] å·²åŠ è½½å†å²æº¯æºæ¡£æ¡ˆï¼ˆæ±‡æ€» {len(updates)} æ¡ updates æ£€ç´¢ï¼‰...")
        except Exception:
            rag_knowledge = "(RAG Database Unavailable)"

        # --- Phase 2: æ„é€ æ‰¹é‡ Prompt ---
        time_info = alert_batch.get("time_window", {})
        tw_str = f"æ—¶é—´çª—å£: {time_info.get('start', 'N/A')} ~ {time_info.get('end', 'N/A')}\n" if time_info else ""

        updates_text = "\n".join([
            f"  [{i+1}] prefix={u.get('prefix')} | as_path={u.get('as_path')} | "
            f"detected_origin={u.get('detected_origin')} | expected_origin={u.get('expected_origin')}"
            for i, u in enumerate(updates)
        ])

        dynamic_prompt = f"""
{self.batch_system_prompt}

ã€ğŸ“‚ å†å²æº¯æºæ¡£æ¡ˆ (RAG Reference)ã€‘
{rag_knowledge}

ã€ğŸš¨ æ‰¹é‡å‘Šè­¦è¯æ® (Batch Evidence)ã€‘
{tw_str}
å…± {len(updates)} æ¡å¯ç–‘ Update æ¶ˆæ¯:
{updates_text}

è¯·æ±‡æ€»ä»¥ä¸Šæ‰€æœ‰ updatesï¼Œç»¼åˆåˆ¤æ–­ï¼š**åŸºäºç›®å‰å¼‚å¸¸å‘Šè­¦æ¶ˆæ¯ï¼Œæœ€æœ‰å¯èƒ½æ˜¯æ”»å‡»è€…çš„ AS å·**ã€‚
"""
        messages = [
            {"role": "system", "content": dynamic_prompt},
            {"role": "user", "content": "è¯·åˆ†æä¸Šè¿°æ‰¹é‡å‘Šè­¦ï¼Œä½¿ç”¨ path_forensics ç­‰å·¥å…·ç»¼åˆæº¯æºï¼Œè¾“å‡º most_likely_attacker åŠ confidenceã€‚"}
        ]

        trace = {
            "target": alert_batch,
            "start_time": datetime.now().isoformat(),
            "rag_context": rag_knowledge,
            "chain_of_thought": [],
            "final_result": None
        }

        # --- Phase 3: æ¨ç†å¾ªç¯ ---
        for round_idx in range(1, 4):
            if verbose:
                print(f"--- Round {round_idx} ---")

            resp_json = await self._call_llm(messages)
            if not resp_json:
                break

            tool_req = resp_json.get("tool_request")
            final_decision = resp_json.get("final_decision")

            if tool_req:
                if isinstance(tool_req, dict):
                    tool_req = list(tool_req.values())[0]
                tool_req = str(tool_req).strip()
                if tool_req.lower() == "none":
                    tool_req = None

            step_record = {
                "round": round_idx,
                "thought": resp_json.get("thought_process"),
                "ai_full_response": resp_json,
                "tool_used": tool_req,
                "tool_output": None
            }

            if tool_req:
                if verbose:
                    print(f"ğŸ› ï¸  Agent è°ƒç”¨å·¥å…·: {tool_req}")
                tool_output = self.toolkit.call_tool(tool_req, alert_batch, is_batch=True)
                step_record["tool_output"] = tool_output
                trace["chain_of_thought"].append(step_record)

                messages.append({"role": "assistant", "content": json.dumps(resp_json)})
                messages.append({"role": "user", "content": f"ã€å·¥å…·ç»“æœã€‘\n{tool_output}\n\nè¯·ç»¼åˆä»¥ä¸Šç»“æœåˆ¤æ–­ï¼šæœ€æœ‰å¯èƒ½æ˜¯æ”»å‡»è€…çš„ ASï¼Ÿè‹¥èƒ½ç¡®å®šï¼Œè¯·è¾“å‡º final_decisionï¼ˆå« most_likely_attacker ä¸ confidenceï¼‰ã€‚"})
                continue

            if final_decision:
                trace["final_result"] = final_decision
                trace["chain_of_thought"].append(step_record)
                if verbose:
                    attacker = final_decision.get("most_likely_attacker", final_decision.get("attacker_as", "Unknown"))
                    conf = final_decision.get("confidence", "")
                    print(f"âœ… ç»“æ¡ˆ! æœ€å¯èƒ½æ”»å‡»è€…: {attacker} (ç½®ä¿¡åº¦: {conf})")
                self._save_report(trace, is_batch=True)
                return trace

            trace["chain_of_thought"].append(step_record)
            messages.append({"role": "assistant", "content": json.dumps(resp_json)})
            messages.append({"role": "user", "content": "è¯·ç»§ç»­åˆ†æã€‚"})

        # --- Phase 4: å¼ºåˆ¶ç»“ç®— ---
        if trace["final_result"] is None:
            if verbose:
                print("âš ï¸ å¼ºåˆ¶ç»“æ¡ˆ...")
            messages.append({"role": "user", "content": "åˆ†æç»“æŸã€‚è¯·ç«‹å³è¾“å‡º JSONï¼Œå¿…é¡»åŒ…å« most_likely_attacker å’Œ confidenceã€‚"})
            final_resp = await self._call_llm(messages)
            if final_resp and final_resp.get("final_decision"):
                trace["final_result"] = final_resp.get("final_decision")
                trace["chain_of_thought"].append({
                    "round": "force",
                    "thought": final_resp.get("thought_process"),
                    "ai_full_response": final_resp,
                    "tool_used": None,
                    "tool_output": None,
                })

        self._save_report(trace, is_batch=True)
        return trace

if __name__ == "__main__":
    import sys
    agent = BGPAgent()

    # æ‰¹é‡æ¨¡å¼ï¼šå¤šæ¡å‘Šè­¦ç»¼åˆæº¯æº
    if len(sys.argv) > 1 and sys.argv[1] == "batch":
        batch_case = {
            "time_window": {"start": "2024-01-15T10:00:00", "end": "2024-01-15T10:30:00"},
            "updates": [
                {"prefix": "8.8.8.0/24", "as_path": "701 174", "detected_origin": "174", "expected_origin": "15169"},
                {"prefix": "8.8.8.0/24", "as_path": "701 174", "detected_origin": "174", "expected_origin": "15169"},
                {"prefix": "8.8.8.0/24", "as_path": "3356 4761", "detected_origin": "4761", "expected_origin": "15169"},
            ]
        }
        asyncio.run(agent.diagnose_batch(batch_case, verbose=True))
    else:
        # å•æ¡æ¨¡å¼ï¼šæ¨¡æ‹Ÿ Google 2005 çœŸå®åŠ«æŒæ¡ˆ
        test_case = {
            "prefix": "64.233.161.0/24",
            "as_path": "701 174",
            "detected_origin": "174",
            "expected_origin": "15169"
        }
        asyncio.run(agent.diagnose(test_case, verbose=True))