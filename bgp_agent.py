import asyncio
import json
import re
from openai import AsyncOpenAI
from tools.bgp_toolkit import BGPToolKit  # å¯¼å…¥åˆšæ‰åšå¥½çš„å·¥å…·ç®±

# --- é…ç½® ---
API_KEY = "sk-9944c48494394db6b8bc31b40f8a710f"
BASE_URL = "https://api.deepseek.com"

class BGPAgent:
    def __init__(self):
        self.client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)
        self.toolkit = BGPToolKit()
        
        # å®šä¹‰ç³»ç»Ÿäººè®¾å’Œå¯ç”¨å·¥å…·è¯´æ˜
        self.system_prompt = """
ä½ æ˜¯ä¸€ä¸ªé«˜çº§ BGP å®‰å…¨åˆ†æä¸“å®¶ (Agent)ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¯¹ BGP å¼‚å¸¸å‘Šè­¦è¿›è¡Œæ ¹å› åˆ†æ (RCA)ã€‚
ä½ æ‹¥æœ‰ä»¥ä¸‹å·¥å…·ç®±ï¼Œè¯·æ ¹æ®éœ€è¦ç”³è¯·è°ƒç”¨å·¥å…·æ¥éªŒè¯ä½ çš„å‡è®¾ï¼š

1. `authority_check`: æŸ¥è¯¢ RPKI/ROA æˆæƒçŠ¶æ€ (æ£€æµ‹éæ³•å®£å‘Š)ã€‚
2. `geo_check`: æ£€æµ‹ IP ä¸ Origin AS çš„åœ°ç†ä½ç½®å†²çª (æ£€æµ‹è·¨å›½åŠ«æŒ)ã€‚
3. `neighbor_check`: åˆ†æä¼ æ’­è¯¥è·¯ç”±çš„ä¸Šæ¸¸é‚»å±… (Tier-1/ISP)ã€‚
4. `topology_check`: æ£€æŸ¥ AS è·¯å¾„æ˜¯å¦è¿èƒŒå•†ä¸šé€»è¾‘ (Valley-Free)ã€‚
5. `stability_analysis`: æŸ¥è¯¢è¯¥å‰ç¼€çš„å†å²æ›´æ–°é¢‘ç‡ã€‚

**äº¤äº’è§„åˆ™ï¼š**
1. æ¯æ¬¡å›å¤å¿…é¡»ä¸¥æ ¼éµå¾ª JSON æ ¼å¼ã€‚
2. å³ä½¿ä½ è®¤ä¸ºè¯æ®å·²ç»è¶³å¤Ÿï¼Œä¹Ÿå¿…é¡»è¾“å‡º JSONã€‚
3. è¿™æ˜¯ä¸€ä¸ªå¤šè½®å¯¹è¯ï¼Œä½ ä¼šåˆ†é˜¶æ®µè·å–ä¿¡æ¯ã€‚

**JSON è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
{
    "thought_process": "ç®€è¿°ä½ å½“å‰çš„åˆ†ææ€è·¯...",
    "needs_more_evidence": true/false,
    "tool_requests": ["tool_name1", "tool_name2"],  // å¦‚æœä¸éœ€è¦å·¥å…·ï¼Œå¡« []
    "final_diagnosis": {                             // ä»…å½“ needs_more_evidence ä¸º false æ—¶å¡«å†™
        "status": "MALICIOUS_HIJACK" | "CONFIGURATION_ERROR" | "BENIGN",
        "confidence_score": 0-100,
        "summary": "æœ€ç»ˆçš„æ ¹å› åˆ†ææŠ¥å‘Š..."
    }
}
"""

    async def _call_llm(self, messages):
        """è°ƒç”¨ DeepSeek å¹¶è§£æ JSON"""
        try:
            response = await self.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                response_format={'type': 'json_object'}, # å¼ºåˆ¶ JSON æ¨¡å¼
                temperature=0.1 # é™ä½éšæœºæ€§ï¼Œä¿è¯é€»è¾‘ä¸¥å¯†
            )
            content = response.choices[0].message.content
            # æ¸…æ´—å¯èƒ½å­˜åœ¨çš„ markdown æ ‡è®°
            content = re.sub(r"```json|```", "", content).strip()
            return json.loads(content)
        except Exception as e:
            print(f"âŒ LLM è°ƒç”¨æˆ–è§£æå¤±è´¥: {e}")
            return None

    async def diagnose(self, alert_context):
        """æ‰§è¡Œä¸‰å±‚è¿½é—®è¯Šæ–­æµç¨‹"""
        print(f"\nğŸ›¡ï¸  [Agent å¯åŠ¨] å¼€å§‹è¯Šæ–­å‰ç¼€: {alert_context['prefix']}")
        
        # åˆå§‹åŒ–å¯¹è¯å†å²
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": f"æ£€æµ‹åˆ°å¼‚å¸¸ BGP æ›´æ–°ï¼š{json.dumps(alert_context)}ã€‚è¯·å¼€å§‹åˆ†æã€‚"}
        ]

        # æœ€å¤šè¿›è¡Œ 3 è½®è¿½é—® (é˜²æ­¢æ­»å¾ªç¯)
        max_rounds = 3
        
        for round_idx in range(1, max_rounds + 1):
            print(f"\n--- ç¬¬ {round_idx} è½®æ€è€ƒ (Layer {round_idx}) ---")
            
            # 1. AI æ€è€ƒ
            response_json = await self._call_llm(messages)
            if not response_json: break
            
            print(f"ğŸ§  æ€ç»´é“¾: {response_json.get('thought_process')}")

            # 2. åˆ¤æ–­æ˜¯å¦ç»“æŸ
            if not response_json.get("needs_more_evidence", False):
                print("âœ… è¯Šæ–­å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€‚")
                return response_json.get("final_diagnosis")

            # 3. æ‰§è¡Œå·¥å…·è°ƒç”¨ (Action)
            tools_to_run = response_json.get("tool_requests", [])
            if not tools_to_run:
                print("âš ï¸ AI è¡¨ç¤ºéœ€è¦è¯æ®ä½†æœªæŒ‡å®šå·¥å…·ï¼Œå¼ºåˆ¶ç»“æŸã€‚")
                break

            tool_outputs = []
            print(f"ğŸ› ï¸  AI ç”³è¯·è°ƒç”¨å·¥å…·: {tools_to_run}")
            
            for tool_name in tools_to_run:
                # å®é™…è°ƒç”¨ bgp_toolkit
                result = self.toolkit.call_tool(tool_name, alert_context)
                print(f"    -> {result}")
                tool_outputs.append(result)

            # 4. å°†å·¥å…·ç»“æœåé¦ˆç»™ AI (Observation)
            feedback_msg = f"å·¥å…·æ‰§è¡Œç»“æœå¦‚ä¸‹ï¼š\n" + "\n".join(tool_outputs) + "\nè¯·æ ¹æ®è¿™äº›æ–°è¯æ®ç»§ç»­åˆ†æã€‚"
            messages.append({"role": "assistant", "content": json.dumps(response_json)})
            messages.append({"role": "user", "content": feedback_msg})

        return None

# --- æµ‹è¯•å…¥å£ ---
if __name__ == "__main__":
    # æ¨¡æ‹Ÿ Twitter 2022 çœŸå®åŠ«æŒæ•°æ®
    # AS12389 (Rostelecom) åŠ«æŒ AS13414 (Twitter)
    test_alert = {
        "prefix": "104.244.42.0/24",
        "as_path": "174 12389",  # Cogent -> Rostelecom
        "timestamp": 1648474800,
        "anomaly_score": 0.85
    }

    agent = BGPAgent()
    
    # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
    loop = asyncio.get_event_loop()
    final_report = loop.run_until_complete(agent.diagnose(test_alert))

    if final_report:
        print("\n" + "="*40)
        print("ğŸ“ æœ€ç»ˆ RCA æŠ¥å‘Š (Root Cause Analysis)")
        print("="*40)
        print(f"åˆ¤å®šçŠ¶æ€: {final_report['status']}")
        print(f"ç½®ä¿¡åº¦:   {final_report['confidence_score']}/100")
        print(f"è¯¦ç»†æ€»ç»“: {final_report['summary']}")
        print("="*40)