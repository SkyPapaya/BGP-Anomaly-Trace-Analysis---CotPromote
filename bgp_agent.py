import asyncio
import json
import os
import re
from datetime import datetime
from openai import AsyncOpenAI
from tools.bgp_toolkit import BGPToolKit

# --- é…ç½® ---
API_KEY = "sk-9944c48494394db6b8bc31b40f8a710f"
BASE_URL = "https://api.deepseek.com"

class BGPAgent:
    def __init__(self, report_dir="./report"):
        self.client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)
        self.toolkit = BGPToolKit()
        
        # æŠ¥å‘Šå­˜å‚¨è·¯å¾„
        self.report_dir = report_dir
        
        self.system_prompt = """
ä½ æ˜¯ä¸€ä¸ª BGP å®‰å…¨ä¸“å®¶ Agentã€‚ä½ çš„ç›®æ ‡æ˜¯é€šè¿‡å¤šè½®æ’æŸ¥ï¼Œç¡®å®šä¸€ä¸ª BGP æ›´æ–°æ˜¯å¦ä¸ºæ¶æ„åŠ«æŒã€‚
**å¯ç”¨å·¥å…·ç®± (ä¸¥ç¦ä½¿ç”¨é™¤æ­¤ä¹‹å¤–çš„ä»»ä½•å·¥å…·):**
1. `authority_check`: æŸ¥è¯¢ RPKI æˆæƒçŠ¶æ€ (æ£€æŸ¥ Origin AS æ˜¯å¦åˆæ³•)ã€‚
2. `geo_check`: æ£€æŸ¥ IP å’Œ ASN çš„åœ°ç†ä½ç½® (æ£€æŸ¥è·¨å›½å†²çª)ã€‚
3. `neighbor_check`: æ£€æŸ¥ä¼ æ’­è¯¥è·¯ç”±çš„ä¸Šæ¸¸é‚»å±… (AS 174, 3356 ç­‰)ã€‚
4. `topology_check`: æ£€æŸ¥ AS è·¯å¾„çš„å•†ä¸šå…³ç³» (æ£€æŸ¥è·¯ç”±æ³„éœ²)ã€‚

**å·¥ä½œæµç¨‹ä¸â€œæ­»çº¿â€æœºåˆ¶ï¼š**
è¿™æ˜¯ä¸€ä¸ªæœ€å¤š 3 è½®çš„å¯¹è¯ã€‚
1. åœ¨ç¬¬ 1 è½®å’Œç¬¬ 2 è½®ï¼šå¦‚æœè¯æ®ä¸è¶³ï¼Œä¼˜å…ˆç”³è¯·å·¥å…·ã€‚
2. **åœ¨ç¬¬ 3 è½®ï¼ˆæœ€åä¸€è½®ï¼‰ï¼šä½ å¿…é¡»æ ¹æ®å½“å‰æ‰€æœ‰å·²çŸ¥ä¿¡æ¯ï¼Œå¼ºåˆ¶ç»™å‡º final_decisionã€‚ä¸¥ç¦åœ¨ç¬¬ 3 è½®ç”³è¯·å·¥å…·æˆ–è¿”å› final_decision ä¸º nullã€‚**

**è¾“å‡ºæ ¼å¼è¦æ±‚ (å¿…é¡»æ˜¯ JSON)ï¼š**
{
    "round_id": int,
    "thought_process": "string",
    "suspicion_level": "low/medium/high", 
    "tool_request": "string",  // ç¬¬ 3 è½®å¿…é¡»ä¸º null
    "final_decision": {        // ç¬¬ 3 è½®æˆ–è¯æ®ç¡®å‡¿æ—¶å¿…é¡»å¡«å†™
        "status": "MALICIOUS" | "BENIGN" | "UNKNOWN",
        "summary": "æœ€ç»ˆç»“è®º..."
    }
}
"""

    async def _call_llm(self, messages):
        try:
            response = await self.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                response_format={'type': 'json_object'},
                temperature=0.0
            )
            content = response.choices[0].message.content
            return json.loads(content)
        except Exception as e:
            return {"error": str(e)}

    def _save_report_to_disk(self, trace_data):
        """å†…éƒ¨æ–¹æ³•ï¼šå°†è¯Šæ–­ç»“æœå†™å…¥ç¡¬ç›˜"""
        # 1. ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(self.report_dir):
            try:
                os.makedirs(self.report_dir, exist_ok=True)
            except Exception as e:
                print(f"âŒ æ— æ³•åˆ›å»ºç›®å½• {self.report_dir}: {e}")
                return

        # 2. ç”Ÿæˆæ–‡ä»¶å
        # å®‰å…¨å¤„ç†: å°† 104.244.42.0/24 è½¬æ¢ä¸º 104.244.42.0_24
        raw_prefix = trace_data.get("target", {}).get("prefix", "unknown")
        safe_prefix = raw_prefix.replace("/", "_")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        filename = f"analysis_{safe_prefix}_{timestamp}.json"
        file_path = os.path.join(self.report_dir, filename)

        # 3. å†™å…¥æ–‡ä»¶
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(trace_data, f, indent=4, ensure_ascii=False)
            print(f"ğŸ’¾ [Agent] æŠ¥å‘Šå·²è‡ªåŠ¨å½’æ¡£: {file_path}")
        except Exception as e:
            print(f"âŒ [Agent] æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")

    async def diagnose(self, alert_context, verbose=False):
        """
        æ‰§è¡Œè¯Šæ–­æµç¨‹ï¼Œå¹¶è‡ªåŠ¨ä¿å­˜æŠ¥å‘Šåˆ°æŒ‡å®šç›®å½•ã€‚
        """
        if verbose:
            print(f"\nğŸ›¡ï¸  [Agent] å¼€å§‹è¯Šæ–­: {alert_context.get('prefix')}...")

        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": f"ã€ç³»ç»Ÿå‘Šè­¦ã€‘æ£€æµ‹åˆ°å¼‚å¸¸è·¯ç”±æ›´æ–°ï¼š\n{json.dumps(alert_context)}\nè¯·å¼€å§‹åˆ†æã€‚"}
        ]
        
        full_trace = {
            "target": alert_context,
            "start_time": datetime.now().isoformat(),
            "chain_of_thought": [],
            "final_result": None
        }

        for round_idx in range(1, 4):
            if verbose: print(f"--- Round {round_idx} ---")
            
            # 1. AI æ€è€ƒ
            response_json = await self._call_llm(messages)
            if not response_json: break
            
            trace_item = {
                "round": round_idx,
                "ai_thought": response_json.get("thought_process"),
                "suspicion": response_json.get("suspicion_level"),
                "tool_used": response_json.get("tool_request"),
                "tool_output": None
            }

            # 2. æ£€æŸ¥ç»“è®º
            final_decision = response_json.get("final_decision")
            if final_decision:
                full_trace["final_result"] = final_decision
                full_trace["chain_of_thought"].append(trace_item)
                if verbose: print("âœ… è¯Šæ–­ç»“æŸã€‚")
                
                # --- å…³é”®ä¿®æ”¹ï¼šé€€å‡ºå‰è‡ªåŠ¨ä¿å­˜ ---
                self._save_report_to_disk(full_trace)
                return full_trace

            # 3. æ‰§è¡Œå·¥å…·
            tool_name = response_json.get("tool_request")
            tool_result_str = "æœªè¯·æ±‚å·¥å…·ã€‚"
            
            if tool_name:
                if verbose: print(f"ğŸ› ï¸  Calling: {tool_name}")
                tool_result_str = self.toolkit.call_tool(tool_name, alert_context)
                trace_item["tool_output"] = tool_result_str

            full_trace["chain_of_thought"].append(trace_item)

            # 4. æ›´æ–°ä¸Šä¸‹æ–‡
            messages.append({"role": "assistant", "content": json.dumps(response_json)})
            messages.append({"role": "user", "content": f"ã€å·¥å…·ç»“æœã€‘\n{tool_result_str}\n\nè¯·ç»§ç»­åˆ†æã€‚"})

            #5. å¾ªç¯ç»“æŸåçš„å¼ºåˆ¶ç»“ç®— ---
        if full_trace["final_result"] is None:
            if verbose: print("âš ï¸ è¾¾åˆ°æœ€å¤§è½®æ¬¡æœªå‡ºç»“è®ºï¼Œå¼ºåˆ¶è¿›è¡Œæœ€ç»ˆåˆ¤å®š...")
            
            # æ„é€ ä¸€æ¡å¼ºåˆ¶æŒ‡ä»¤
            messages.append({
                "role": "user", 
                "content": "ã€ç³»ç»ŸæŒ‡ä»¤ã€‘å·²è¾¾åˆ°æœ€å¤§åˆ†æè½®æ¬¡ã€‚è¯·å¿½ç•¥æœªå®Œæˆçš„å·¥å…·è°ƒç”¨ï¼Œæ ¹æ®ç°æœ‰çš„ RPKIã€åœ°ç†ä½ç½®å’Œ AS è·¯å¾„è¯æ®ï¼Œå¿…é¡»ç«‹å³ç”Ÿæˆ final_decision JSONã€‚"
            })
            
            # æœ€åè°ƒç”¨ä¸€æ¬¡ LLM
            final_resp = await self._call_llm(messages)
            
            if final_resp and final_resp.get("final_decision"):
                full_trace["final_result"] = final_resp.get("final_decision")
                # è®°å½•è¿™ä¸€è½®â€œå¼ºåˆ¶æ€è€ƒâ€
                full_trace["chain_of_thought"].append({
                    "round": "Final_Summary",
                    "ai_thought": final_resp.get("thought_process", "Forced Summary"),
                    "suspicion": final_resp.get("suspicion_level"),
                    "tool_used": None,
                    "tool_output": None
                })

        # å¦‚æœå¾ªç¯ç»“æŸè¿˜æ²¡æœ‰ç»“è®ºï¼Œä¹Ÿä¿å­˜å½“å‰çŠ¶æ€
        self._save_report_to_disk(full_trace)
        return full_trace

if __name__ == "__main__":
    # ç®€å•è‡ªæµ‹
    agent = BGPAgent() # é»˜è®¤è·¯å¾„ /home/skypapaya/code/report
    test_data = {"prefix": "1.1.1.0/24", "as_path": "174 13335"} 
    asyncio.run(agent.diagnose(test_data, verbose=True))