import asyncio
import json
import os
import traceback  # å¼•å…¥è¿™ä¸ªä»¥ä¾¿æ‰“å°æŠ¥é”™ç»†èŠ‚
from datetime import datetime
from openai import AsyncOpenAI
from tools.bgp_toolkit import BGPToolKit
from tools.rag_manager import RAGManager

# --- é…ç½® ---
API_KEY = "sk-9944c48494394db6b8bc31b40f8a710f"
BASE_URL = "https://api.deepseek.com"

class BGPAgent:
    def __init__(self, report_dir="./report"):
        self.client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)
        self.toolkit = BGPToolKit()
        # ç¡®ä¿è·¯å¾„ä¸ build_vector_db.py ä¸­ä¸€è‡´
        self.rag = RAGManager(db_path="./rag_db") 
        self.report_dir = report_dir

        # ==========================================
        # ğŸ¯ æ ¸å¿ƒä¿®æ”¹ï¼šå¼ºåŒ– Prompt çš„æ ¼å¼çº¦æŸ
        # ==========================================
        self.base_system_prompt = """
ä½ æ˜¯ä¸€ä¸ª BGP å®‰å…¨ä¸“å®¶ Agentã€‚ä½ çš„ç›®æ ‡æ˜¯ç»“åˆã€å†å²æ¡ˆä¾‹çŸ¥è¯†ã€‘å’Œã€å®æ—¶å·¥å…·æ£€æµ‹ã€‘ï¼Œå¯¹ BGP å¼‚å¸¸è¿›è¡Œå®šæ€§ã€‚

**å¯ç”¨å·¥å…·æ¸…å•:**
1. `authority_check`: æŸ¥è¯¢ RPKI æˆæƒçŠ¶æ€ã€‚
2. `geo_check`: æ£€æŸ¥åœ°ç†ä½ç½®å†²çªã€‚
3. `neighbor_check`: æ£€æŸ¥ä¸Šæ¸¸é‚»å±…ä¿¡èª‰ã€‚
4. `topology_check`: æ£€æŸ¥ AS è·¯å¾„å•†ä¸šå…³ç³» (Valley-Free)ã€‚
5. `graph_analysis`: æŸ¥è¯¢çŸ¥è¯†å›¾è°±ï¼Œæ£€æŸ¥ Origin ä¸ Owner çš„çœŸå®æ‹“æ‰‘è·ç¦»ã€‚

**âš ï¸ ä¸¥æ ¼è¾“å‡ºæ ¼å¼çº¦æŸ (JSON):**
ä½ å¿…é¡»æ¯ä¸€æ¬¡å›å¤éƒ½åªè¾“å‡ºä¸€ä¸ªæ ‡å‡†çš„ JSON å¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
    "thought_process": "ä½ çš„æ€è€ƒè¿‡ç¨‹...",
    "suspicion_level": "LOW" | "MEDIUM" | "HIGH",
    "tool_request": "å·¥å…·åç§°å­—ç¬¦ä¸²" OR null, 
    "final_decision": null OR { "status": "MALICIOUS/LEAK/BENIGN", "summary": "..." }
}

**âŒ ç¦å¿Œäº‹é¡¹:**
1. `tool_request` å­—æ®µå¿…é¡»æ˜¯ **å­—ç¬¦ä¸² (String)** (ä¾‹å¦‚ "graph_analysis") æˆ– nullã€‚
2. **ä¸¥ç¦** åœ¨ `tool_request` ä¸­è¿”å›å¯¹è±¡/å­—å…¸ (ä¾‹å¦‚ {"name": "graph_analysis"} æ˜¯é”™è¯¯çš„ï¼)ã€‚
3. å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œ`final_decision` å¿…é¡»ä¸º nullã€‚
4. åªæœ‰åœ¨æ”¶é›†åˆ°è¶³å¤Ÿè¯æ®åï¼Œæ‰å°† `tool_request` è®¾ä¸º null å¹¶å¡«å…… `final_decision`ã€‚
"""

    async def _call_llm(self, messages):
        """è°ƒç”¨ DeepSeek å¤§æ¨¡å‹"""
        try:
            response = await self.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                response_format={'type': 'json_object'}, # å¼ºåˆ¶ JSON æ¨¡å¼
                temperature=0.0 # 0 æ¸©åº¦ä¿è¯é€»è¾‘ä¸¥è°¨
            )
            content = response.choices[0].message.content
            return json.loads(content)
        except Exception as e:
            print(f"âŒ API è°ƒç”¨å¤±è´¥: {e}")
            return {"thought_process": f"API Error: {str(e)}", "tool_request": None}

    def _save_report_to_disk(self, trace_data):
        """ä¿å­˜æŠ¥å‘Š"""
        if not os.path.exists(self.report_dir):
            os.makedirs(self.report_dir, exist_ok=True)

        raw_prefix = trace_data.get("target", {}).get("prefix", "unknown")
        safe_prefix = raw_prefix.replace("/", "_")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"analysis_{safe_prefix}_{timestamp}.json"
        file_path = os.path.join(self.report_dir, filename)

        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(trace_data, f, indent=4, ensure_ascii=False)
            # print(f"ğŸ’¾ æŠ¥å‘Šå½’æ¡£: {filename}")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

    async def diagnose(self, alert_context, verbose=False):
        if verbose: print(f"\nğŸ›¡ï¸  [Agent] å¼€å§‹è¯Šæ–­: {alert_context.get('prefix')}...")

        # --- Phase 1: RAG æ£€ç´¢ ---
        try:
            retrieved_knowledge = self.rag.search_similar_cases(alert_context, k=2)
            if verbose and "æœªæ‰¾åˆ°" not in str(retrieved_knowledge):
                print(f"ğŸ“š [RAG å‘½ä¸­] æ£€ç´¢åˆ°å†å²æ¡ˆä¾‹å‚è€ƒ...")
        except Exception:
            retrieved_knowledge = "(RAG æš‚æ—¶ä¸å¯ç”¨)"

        # --- Phase 2: æ„å»º Prompt ---
        dynamic_prompt = f"""
{self.base_system_prompt}

ã€ğŸ§  å†å²çŸ¥è¯†åº“å‚è€ƒ (RAG)ã€‘
{retrieved_knowledge}

ã€å½“å‰å¾…åˆ†æå‘Šè­¦ã€‘
Prefix: {alert_context.get('prefix')}
Path: {alert_context.get('as_path')}
Origin: {alert_context.get('detected_origin')}
Expected Origin: {alert_context.get('expected_origin')}
"""
        messages = [
            {"role": "system", "content": dynamic_prompt},
            {"role": "user", "content": "æ£€æµ‹åˆ° BGP å¼‚å¸¸ï¼Œè¯·ä¸¥æ ¼æŒ‰ JSON æ ¼å¼è¾“å‡ºåˆ†æã€‚"}
        ]
        
        full_trace = {
            "target": alert_context,
            "start_time": datetime.now().isoformat(),
            "rag_context": retrieved_knowledge,
            "chain_of_thought": [],
            "final_result": None
        }

        # --- Phase 3: å¤šè½®æ¨ç† ---
        for round_idx in range(1, 4):
            if verbose: print(f"--- Round {round_idx} ---")
            
            response_json = await self._call_llm(messages)
            if not response_json: break
            
            # æå–å…³é”®å­—æ®µ
            tool_name_raw = response_json.get("tool_request")
            final_decision = response_json.get("final_decision")

            # ==========================================
            # ğŸ›¡ï¸ ä»£ç é˜²å¾¡ï¼šé˜²æ­¢ "unhashable type: dict"
            # å³ä½¿ Prompt å†™å¾—å†å¥½ï¼Œä¹Ÿè¦é˜²æ­¢ AI å¶å°”æŠ½é£
            # ==========================================
            tool_name = tool_name_raw
            if tool_name_raw:
                # 1. å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå– values
                if isinstance(tool_name_raw, dict):
                    if verbose: print(f"âš ï¸ [è‡ªåŠ¨ä¿®æ­£] AI è¿”å›äº†å­—å…¸æ ¼å¼: {tool_name_raw}")
                    # å°è¯•å–ç¬¬ä¸€ä¸ª valueï¼Œæˆ–è€…æ˜¯ 'name' å­—æ®µ
                    tool_name = tool_name_raw.get('name') or tool_name_raw.get('tool') or list(tool_name_raw.values())[0]
                
                # 2. å¼ºåˆ¶è½¬ä¸ºå­—ç¬¦ä¸²å¹¶å»ç©ºæ ¼
                tool_name = str(tool_name).strip()
                
                # 3. å¤„ç† "None" å­—ç¬¦ä¸²çš„æƒ…å†µ
                if tool_name.lower() == "none":
                    tool_name = None

            trace_item = {
                "round": round_idx,
                "ai_thought": response_json.get("thought_process"),
                "tool_used": tool_name, # è®°å½•ä¿®æ­£åçš„åå­—
                "tool_output": None
            }

            # é€»è¾‘åˆ†æ”¯ï¼šä¼˜å…ˆæ‰§è¡Œå·¥å…·
            if tool_name:
                if verbose: print(f"ğŸ› ï¸  Agent è°ƒç”¨å·¥å…·: {tool_name}")
                
                # è¿™é‡Œç°åœ¨è‚¯å®šæ˜¯å®‰å…¨çš„å­—ç¬¦ä¸²äº†
                tool_result_str = self.toolkit.call_tool(tool_name, alert_context)
                trace_item["tool_output"] = tool_result_str
                
                full_trace["chain_of_thought"].append(trace_item)
                
                # å°†ç»“æœå–‚å›ç»™ AI
                messages.append({"role": "assistant", "content": json.dumps(response_json)})
                messages.append({"role": "user", "content": f"ã€å·¥å…·åé¦ˆã€‘\n{tool_result_str}\n\nè¯·ç»§ç»­åˆ†æã€‚å¦‚æœè¯æ®ä¸è¶³å¯ç»§ç»­è°ƒç”¨å…¶ä»–å·¥å…·ï¼›å¦‚æœè¯æ®ç¡®å‡¿ï¼Œè¯·è¿”å› final_decisionã€‚"})
                continue # è·³è¿‡ä¸‹é¢çš„ç»“æ¡ˆé€»è¾‘

            # å¦‚æœæ²¡æœ‰å·¥å…·è¯·æ±‚ï¼Œæ£€æŸ¥æ˜¯å¦ç»“æ¡ˆ
            if final_decision:
                full_trace["final_result"] = final_decision
                full_trace["chain_of_thought"].append(trace_item)
                if verbose: print("âœ… è¯Šæ–­ç»“æŸ (AI è‡ªä¸»ç»“æ¡ˆ)ã€‚")
                self._save_report_to_disk(full_trace)
                return full_trace

            # æ—¢æ²¡å·¥å…·ä¹Ÿæ²¡ç»“è®º (ç½•è§)
            full_trace["chain_of_thought"].append(trace_item)
            messages.append({"role": "assistant", "content": json.dumps(response_json)})
            messages.append({"role": "user", "content": "è¯·ç»§ç»­åˆ†æã€‚"})

        # --- Phase 4: å¼ºåˆ¶ç»“ç®— ---
        if full_trace["final_result"] is None:
            if verbose: print("âš ï¸ å¼ºåˆ¶ç»“ç®—...")
            messages.append({"role": "user", "content": "åˆ†æè½®æ¬¡å·²å°½ã€‚è¯·å¿½ç•¥æœªå®Œæˆæ­¥éª¤ï¼Œç«‹å³åŸºäºç°æœ‰ä¿¡æ¯ç”Ÿæˆ final_decision JSONã€‚"})
            final_resp = await self._call_llm(messages)
            if final_resp:
                full_trace["final_result"] = final_resp.get("final_decision")
        
        self._save_report_to_disk(full_trace)
        return full_trace

if __name__ == "__main__":
    agent = BGPAgent()
    test_data = {
        "prefix": "104.244.42.0/24", 
        "as_path": "174 12389", 
        "detected_origin": "12389", 
        "expected_origin": "13414"
    }
    asyncio.run(agent.diagnose(test_data, verbose=True))