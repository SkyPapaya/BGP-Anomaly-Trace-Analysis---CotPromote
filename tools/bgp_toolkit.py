import os
import json
import sys

# å°è¯•å¯¼å…¥ Graph RAG æ¨¡å— (ç”¨äºè¿æ¥ Neo4j)
# ç¡®ä¿ tools ç›®å½•åœ¨ python è·¯å¾„ä¸‹
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from tools.graph_rag import BGPGraphRAG
    GRAPH_RAG_AVAILABLE = True
except ImportError:
    GRAPH_RAG_AVAILABLE = False
    print("âš ï¸ [Warning] graph_rag.py æœªæ‰¾åˆ°ï¼ŒGraph Analysis å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ã€‚")

try:
    from tools.data_provider import BGPDataProvider
    from tools.authority import AuthorityValidator
    from tools.geo import GeoConflictChecker
    from tools.topology import TopologyInspector
    from tools.config_loader import get_risk_asns
    ONLINE_AVAILABLE = True
except ImportError:
    ONLINE_AVAILABLE = False

class BGPToolKit:
    def __init__(self):
        """
        åˆå§‹åŒ– BGP å·¥å…·ç®±
        """
        # å¦‚æœç¯å¢ƒä¸­æœ‰ Neo4j ä¸”ä»£ç å­˜åœ¨ï¼Œåˆå§‹åŒ–å›¾åˆ†æå¼•æ“
        if GRAPH_RAG_AVAILABLE:
            try:
                # æ³¨æ„ï¼šç¡®ä¿è¿™é‡Œçš„å¯†ç å’Œä½  Docker è®¾ç½®çš„ä¸€è‡´ (whm161122309)
                self.graph_engine = BGPGraphRAG(password="whm161122309")
            except Exception as e:
                print(f"âŒ [Error] Neo4j è¿æ¥å¤±è´¥: {e}")
                self.graph_engine = None
        else:
            self.graph_engine = None

    def call_tool(self, tool_name, context, is_batch=False):
        """
        ç»Ÿä¸€å·¥å…·è°ƒç”¨å…¥å£
        :param tool_name: å·¥å…·åç§° (å­—ç¬¦ä¸²)
        :param context: å‘Šè­¦ä¸Šä¸‹æ–‡ (å­—å…¸)ï¼Œæ‰¹é‡æ—¶ä¸º {updates: [...], time_window: {...}}
        :param is_batch: æ˜¯å¦ä¸ºæ‰¹é‡æ¨¡å¼ï¼ˆå¤šæ¡ updates ç»¼åˆæº¯æºï¼‰
        """
        tool_name = str(tool_name).lower().strip()

        if tool_name == "path_forensics":
            return self.path_forensics(context, is_batch=is_batch)

        elif tool_name == "graph_analysis":
            return self.graph_analysis(context, is_batch=is_batch)

        elif tool_name == "authority_check":
            return self.authority_check(context, is_batch=is_batch)

        elif tool_name == "geo_check":
            return self.geo_check(context, is_batch=is_batch)

        elif tool_name == "neighbor_check":
            return self.neighbor_check(context, is_batch=is_batch)

        elif tool_name == "topology_check":
            return self.topology_check(context, is_batch=is_batch)

        else:
            return f"Error: Tool '{tool_name}' is not supported."

    # ==========================================
    # ğŸ” [NEW] æ ¸å¿ƒæº¯æºå·¥å…·
    # ==========================================
    def path_forensics(self, context, is_batch=False):
        """
        ã€æº¯æºæ ¸å¿ƒã€‘è§£æ AS Pathï¼Œè¯†åˆ« Originï¼Œå¹¶é”å®šæ”»å‡»è€…ã€‚
        æ‰¹é‡æ¨¡å¼ï¼šå¯¹æ¯æ¡ update åˆ†æï¼Œæ±‡æ€»ç»Ÿè®¡å„ AS ä½œä¸ºå«Œç–‘äººçš„é¢‘æ¬¡ã€‚
        """
        if is_batch:
            return self._path_forensics_batch(context)

        as_path = context.get("as_path", "")
        expected_origin = context.get("expected_origin", "")

        if not as_path:
            return "ERROR: AS_PATH is empty in context."

        try:
            parts = as_path.replace(",", " ").split()
            path_list = [p.strip() for p in parts if p.strip().isdigit()]

            if not path_list:
                return "ERROR: No valid ASNs found in path."

            observed_origin = path_list[-1]
            upstream_neighbor = path_list[-2] if len(path_list) > 1 else "None (Direct Peer)"

            report = f"[Path Forensics Report]\n"
            report += f"- Analyzed Path sequence: {path_list}\n"
            report += f"- Observed Origin (Last Hop): AS{observed_origin}\n"
            report += f"- Expected Owner: AS{expected_origin}\n"

            if str(observed_origin) != str(expected_origin):
                report += f"\nğŸš¨ [CRITICAL FINDING]: Origin Mismatch!\n"
                report += f"The prefix is being originated by AS{observed_origin}, but belongs to AS{expected_origin}.\n"
                report += f"-> CONCLUSION: AS{observed_origin} is the PRIMARY SUSPECT (Attacker).\n"
                report += f"-> ACTION: Check if AS{observed_origin} has valid authorization (ROA). If not, this is a Hijack."
            else:
                report += f"\nâœ… [STATUS]: Origin matches expected owner.\n"
                report += f"-> NEXT STEP: Check for Route Leak. The Upstream is AS{upstream_neighbor}.\n"
                report += f"   If AS{upstream_neighbor} is a Peer/Customer leaking routes to a Provider, then AS{upstream_neighbor} is the culprit."

            return report

        except Exception as e:
            return f"Error in path forensics analysis: {str(e)}"

    def _path_forensics_batch(self, context):
        """æ‰¹é‡ updates è·¯å¾„å–è¯ï¼šé€æ¡åˆ†æ + æ±‡æ€»ç»Ÿè®¡"""
        updates = context.get("updates", [])
        if not updates:
            return "ERROR: updates ä¸ºç©ºã€‚"

        reports = []
        suspect_counts = {}  # AS -> ä½œä¸ºå«Œç–‘äººå‡ºç°çš„æ¬¡æ•°
        leak_suspect_counts = {}  # AS -> ä½œä¸º Route Leak å«Œç–‘äººçš„æ¬¡æ•°
        benign_count = 0

        for i, u in enumerate(updates):
            as_path = u.get("as_path", "")
            expected_origin = u.get("expected_origin", "")

            if not as_path:
                reports.append(f"[Update {i+1}] ERROR: AS_PATH ä¸ºç©º")
                continue

            try:
                parts = as_path.replace(",", " ").split()
                path_list = [p.strip() for p in parts if p.strip().isdigit()]
                if not path_list:
                    reports.append(f"[Update {i+1}] ERROR: æ— æœ‰æ•ˆ ASN")
                    continue

                observed_origin = path_list[-1]
                upstream = path_list[-2] if len(path_list) > 1 else None

                prefix = u.get("prefix", "?")
                line = f"[Update {i+1}] prefix={prefix} | path={path_list} | origin=AS{observed_origin} | expected=AS{expected_origin}"

                if str(observed_origin) != str(expected_origin):
                    line += " -> ğŸš¨ SUSPECT: AS" + observed_origin
                    suspect_counts[observed_origin] = suspect_counts.get(observed_origin, 0) + 1
                else:
                    if upstream:
                        line += f" -> âš ï¸ LEAK_CHECK: ä¸Šæ¸¸ AS{upstream} å¯èƒ½æ˜¯ Leaker"
                        leak_suspect_counts[upstream] = leak_suspect_counts.get(upstream, 0) + 1
                    else:
                        line += " -> âœ… BENIGN"
                        benign_count += 1

                reports.append(line)
            except Exception as e:
                reports.append(f"[Update {i+1}] Error: {e}")

        # æ±‡æ€»ç»Ÿè®¡
        agg = "\n\n[ğŸ“Š æ±‡æ€»ç»Ÿè®¡ - ç”¨äºç»¼åˆåˆ¤æ–­æœ€æœ‰å¯èƒ½æ˜¯æ”»å‡»è€…çš„ AS]\n"
        agg += "-" * 50 + "\n"
        if suspect_counts:
            sorted_suspects = sorted(suspect_counts.items(), key=lambda x: -x[1])
            agg += "ä½œä¸º Origin ä¸”ä¸åˆæ³• Owner ä¸ç¬¦çš„ ASï¼ˆå«Œç–‘äººï¼‰:\n"
            for asn, cnt in sorted_suspects:
                agg += f"  AS{asn}: å‡ºç° {cnt} æ¬¡ (å æ¯” {cnt}/{len(updates)})\n"
        if leak_suspect_counts:
            sorted_leak = sorted(leak_suspect_counts.items(), key=lambda x: -x[1])
            agg += "\nRoute Leak æƒ…å¢ƒä¸‹çš„ä¸Šæ¸¸å«Œç–‘ AS:\n"
            for asn, cnt in sorted_leak:
                agg += f"  AS{asn}: {cnt} æ¬¡\n"
        agg += f"\nè‰¯æ€§ update æ•°é‡: {benign_count}/{len(updates)}\n"
        agg += "\nå»ºè®®: å‡ºç°é¢‘æ¬¡æœ€é«˜çš„å«Œç–‘ AS æœ€æœ‰å¯èƒ½æ˜¯æ”»å‡»è€…ï¼›è‹¥å¤šæ¡æŒ‡å‘åŒä¸€ ASï¼Œç½®ä¿¡åº¦æ›´é«˜ã€‚"

        return "\n".join(reports) + agg

    # ==========================================
    # ğŸ•¸ï¸ Graph RAG (å›¾è°±åˆ†æ)
    # ==========================================
    def graph_analysis(self, context, is_batch=False):
        """
        è°ƒç”¨ Neo4j æ£€æŸ¥ Origin å’Œ Owner ä¹‹é—´çš„çœŸå®æ‹“æ‰‘è·ç¦»ã€‚
        æ‰¹é‡æ¨¡å¼ï¼šå¯¹ç¬¬ä¸€æ¡ update è¿›è¡Œåˆ†æï¼ˆæˆ–å¯æ‰©å±•ä¸ºå¯¹æœ€å¯ç–‘çš„ update åˆ†æï¼‰
        """
        ctx = context
        if is_batch:
            updates = context.get("updates", [])
            ctx = updates[0] if updates else context
        if self.graph_engine:
            try:
                print("âš¡ [Toolkit] Calling Neo4j Graph Engine...")
                return self.graph_engine.run_analysis(ctx)
            except Exception as e:
                return f"Graph Engine Error: {str(e)}"
        else:
            observed = ctx.get("detected_origin", "Unknown")
            expected = ctx.get("expected_origin", "Unknown")
            return (f"[Graph ç¦»çº¿] Neo4j æœªè¿æ¥ï¼Œæ— æ³•æŸ¥è¯¢çœŸå®æ‹“æ‰‘ã€‚"
                    f"å»ºè®®è¿è¡Œ tools/import_real_word.py å¯¼å…¥ CAIDA æ•°æ®åå¯ç”¨ Neo4jã€‚"
                    f" Observed AS{observed} vs Expected AS{expected}ã€‚")

    # ==========================================
    # ğŸ›¡ï¸ åŸºç¡€æ£€æµ‹å·¥å…· (æ¨¡æ‹Ÿå®ç°ï¼Œå¯å¯¹æ¥å¤–éƒ¨API)
    # ==========================================
    def authority_check(self, context, is_batch=False):
        """æ£€æŸ¥ RPKI çŠ¶æ€ï¼Œä¼˜å…ˆè”ç½‘æŸ¥è¯¢ RIPEstat APIã€‚æ‰¹é‡æ¨¡å¼ï¼šå¯¹æ¯æ¡ update æ£€æŸ¥å¹¶æ±‡æ€»"""
        if is_batch:
            return self._authority_check_batch(context)
        if ONLINE_AVAILABLE:
            return AuthorityValidator().run(context)
        detected = context.get("detected_origin")
        expected = context.get("expected_origin")
        if str(detected) != str(expected):
            return f"RPKI Status: INVALID. AS{detected} is NOT authorized (offline fallback)."
        return "RPKI Status: VALID."

    def _authority_check_batch(self, context):
        """æ‰¹é‡ RPKI æ£€æŸ¥ï¼Œè”ç½‘æŸ¥è¯¢"""
        updates = context.get("updates", [])
        if not updates:
            return "æ—  updates"
        validator = AuthorityValidator() if ONLINE_AVAILABLE else None
        lines = []
        invalid_asns = {}
        for i, u in enumerate(updates):
            if validator:
                res = validator.run(u)
                lines.append(f"[Update {i+1}] {res}")
                if "INVALID" in res:
                    origin = u.get("detected_origin", u.get("as_path", "").split()[-1] if u.get("as_path") else "?")
                    invalid_asns[origin] = invalid_asns.get(origin, 0) + 1
            else:
                detected = u.get("detected_origin")
                expected = u.get("expected_origin")
                prefix = u.get("prefix", "?")
                if str(detected) != str(expected):
                    lines.append(f"[Update {i+1}] INVALID: AS{detected} éæ³•å®£å‘Š {prefix}")
                    invalid_asns[detected] = invalid_asns.get(detected, 0) + 1
                else:
                    lines.append(f"[Update {i+1}] VALID: AS{detected}")
        if invalid_asns:
            lines.append(f"\næ±‡æ€»: éæ³• Origin AS å‡ºç°é¢‘æ¬¡: {dict(invalid_asns)}")
        return "\n".join(lines)

    def geo_check(self, context, is_batch=False):
        """æ£€æŸ¥ AS åœ°ç†ä½ç½®å†²çªï¼Œè”ç½‘æŸ¥è¯¢ RIPEstat MaxMind/Whois"""
        ctx = context.get("updates", [{}])[0] if is_batch and context.get("updates") else context
        if ONLINE_AVAILABLE:
            return GeoConflictChecker().run(ctx)
        return "Geo Check: éœ€è¦è”ç½‘è·å–åœ°ç†ä½ç½®æ•°æ® (RIPEstat API)ã€‚"

    def neighbor_check(self, context, is_batch=False):
        """æ£€æŸ¥ä¸Šæ¸¸é‚»å±…ä¿¡èª‰ï¼Œè”ç½‘è·å– AS ä¿¡æ¯ï¼Œé£é™© AS ä»çŸ¥è¯†åº“è¯»å–"""
        ctx = context.get("updates", [{}])[0] if is_batch and context.get("updates") else context
        path = ctx.get("as_path", "")
        if not path:
            return "EMPTY: æ— è·¯å¾„ä¿¡æ¯"
        parts = path.replace(",", " ").split()
        first_hop = parts[0] if parts else ""
        if ONLINE_AVAILABLE:
            info = BGPDataProvider.get_as_info(first_hop)
            holder = info.get("holder", "Unknown ISP")
            risk_asns = get_risk_asns()
            if first_hop in risk_asns:
                r = risk_asns[first_hop]
                return f"Neighbor Risk: HIGH. [{holder} (AS{first_hop})] - {r.get('reason', 'known incidents')}."
            return f"INFO: è¯¥å¼‚å¸¸è·¯ç”±ç”± [{holder} (AS{first_hop})] ä¼ æ’­ã€‚"
        risk = get_risk_asns()
        if first_hop in risk:
            return f"Neighbor Risk: HIGH. AS{first_hop} åœ¨çŸ¥è¯†åº“ä¸­æ ‡è®°ä¸ºé£é™© ASã€‚"
        return "Neighbor Risk: LOW (æ— çŸ¥è¯†åº“é£é™©æ ‡è®°)ã€‚"

    def topology_check(self, context, is_batch=False):
        """æ£€æŸ¥ Valley-Free å•†ä¸šåŸåˆ™ï¼ŒTier-1 ä»çŸ¥è¯†åº“åŠ è½½ï¼Œè”ç½‘è·å– AS ä¿¡æ¯"""
        ctx = context.get("updates", [{}])[0] if is_batch and context.get("updates") else context
        if ONLINE_AVAILABLE:
            return TopologyInspector().run(ctx)
        return "Topology Check: éœ€è¦ TopologyInspector (è”ç½‘ AS ä¿¡æ¯)ã€‚"